{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Robust training.\n\nThe following code trains a convolutional neural network (CNN) to be robust\nwith respect to the fast sign gradient (FGSM) method.\n\nThe Fast Gradient Sign Method (FGSM) is a simple yet effective method to\ngenerate adversarial images. It constructs an adversarial by adding a small\nperturbation in the direction of the sign of the gradient with respect to the\ninput. The gradient ensures this perturbation locally maximizes the objective,\nwhile the sign ensures that the update is on the boundary of the L-infinity\nball.\n\n## References\n  Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. \"Explaining\n  and harnessing adversarial examples.\" https://arxiv.org/abs/1412.6572\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n\nimport jax\nfrom jax import numpy as jnp\n\nfrom flax import linen as nn\nimport optax\n\nfrom tqdm import tqdm\n\nfrom jaxopt import loss\nfrom jaxopt import OptaxSolver\nfrom jaxopt import tree_util\n\n\ndef normalize(images):\n  \"\"\"Normalizes images to lie in (0,1) and be float32.\"\"\"\n  return jnp.asarray(images).astype(jnp.float32) / 255.\n\ndef load_datasets():\n  \"\"\"Load MNIST train and test datasets into memory.\n  \n  Taken from https://github.com/google/flax/blob/main/examples/mnist/train.py.\n  \"\"\"\n  ds_builder = tfds.builder('mnist')\n  ds_builder.download_and_prepare()\n  train_ds = tfds.as_numpy(ds_builder.as_dataset(split='train', batch_size=-1))\n  test_ds = tfds.as_numpy(ds_builder.as_dataset(split='test', batch_size=-1))\n  train_ds['image'], test_ds['image'] = map(normalize, (train_ds['image'], test_ds['image']))\n  return train_ds, test_ds\n\n\ndef shuffle(ds, rng, batch_size):\n  \"\"\"Shuffles training data set, and returns batched examples.\"\"\"\n  n_train = len(ds['image'])\n  rng_perm, rng = jax.random.split(rng)\n\n  steps_per_epoch = n_train // batch_size\n\n  permutation = jax.random.permutation(rng_perm, n_train)\n  permutation = permutation[:steps_per_epoch * batch_size]  # skip incomplete batch\n  permutation = permutation.reshape((steps_per_epoch, batch_size))\n\n  images, labels = ds['image'][permutation, ...], ds['label'][permutation, ...]\n  return zip(images, labels)\n\nclass CNN(nn.Module):\n  \"\"\"A simple CNN model.\"\"\"\n\n  @nn.compact\n  def __call__(self, x):\n    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n    x = nn.relu(x)\n    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n    x = nn.relu(x)\n    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n    x = jnp.reshape(x, (x.shape[0], -1))\n    x = nn.Dense(features=256)(x)\n    x = nn.relu(x)\n    x = nn.Dense(features=10)(x)\n    return x\n\n\nnet = CNN()\n\n\n@jax.jit\ndef accuracy(params, images, labels):\n  logits = net.apply({\"params\": params}, images)\n  return jnp.mean(jnp.argmax(logits, axis=-1) == labels)\n\n\nlogistic_loss = jax.vmap(loss.multiclass_logistic_loss)\n\n\n@jax.jit\ndef loss_fun(params, l2_regul, images, labels):\n  \"\"\"Compute the loss of the network.\"\"\"\n  logits = net.apply({\"params\": params}, images)\n  sqnorm = tree_util.tree_l2_norm(params, squared=True)\n  loss_value = jnp.mean(logistic_loss(labels, logits))\n  return loss_value + 0.5 * l2_regul * sqnorm\n\n\n@jax.jit\ndef fsgm_attack(image, label, params, l2_regul, epsilon=0.1):\n  \"\"\"Fast sign-gradient attack on the L-infinity ball with radius epsilon.\n\n  Parameters:\n    image: array-like, input data for the CNN\n    label: integer, class label corresponding to image\n    params: tree, parameters of the model to attack\n    l2_regul: float, L2 regularization scale in the loss function\n    epsilon: float, radius of the L-infinity ball.\n\n  Returns:\n    perturbed_image: Adversarial image on the boundary of the L-infinity ball of radius\n      epsilon and centered at image.\n  \"\"\"\n  # compute gradient of the loss wrt to the image\n  grad = jax.grad(loss_fun, argnums=2)(params, l2_regul, image, label)\n  adv_image = image + epsilon * jnp.sign(grad)\n  # clip the image to ensure pixels are between 0 and 1\n  return jnp.clip(adv_image, 0, 1)\n\ntrain_ds, test_ds = load_datasets()\n\n# Initialize solver and parameters.\nsolver = OptaxSolver(opt=optax.adam(1e-3), fun=loss_fun)\nrng = jax.random.PRNGKey(0)\nparams = CNN().init(rng, jnp.ones([1, 28, 28, 1]))[\"params\"]\nl2_regul = 1e-4\n\nn_epochs = 10\nbatch_size = 128\n\nstate = solver.init_state(params)\nrng = jax.random.PRNGKey(0)\n\nfor epoch in range(n_epochs):\n  # Training\n  pbar = tqdm(shuffle(train_ds, rng, batch_size=128),\n              total=train_ds['label'].size // 128)\n  acc = []\n  adv_acc = []\n  for images, labels in pbar:\n\n    images_adv = fsgm_attack(images, labels, params, l2_regul=0.)\n\n    # train on adversarial images\n    params, state = solver.update(params=params, state=state,\n                              l2_regul=l2_regul, images=images_adv, labels=labels)\n    acc.append(accuracy(params, images, labels))\n    adv_acc.append(accuracy(params, images_adv, labels))\n\n  print(f\"Train accuracy: {jnp.mean(jnp.array(acc)): .3f}\")\n  print(f\"Train adversarial accuracy: {jnp.mean(jnp.array(adv_acc)): .3f}\")\n\n  # Testing\n  images_test = test_ds['image']\n  labels_test = test_ds['label']\n\n  test_accuracy = accuracy(params, images_test, labels_test)\n  print(\"Test accuracy:\", test_accuracy)\n\n  images_adv_test = fsgm_attack(images_test, labels_test, params, l2_regul=0.)\n  test_adversarial_accuracy = accuracy(params, images_adv_test, labels_test)\n  print(\"Test adversarial accuracy:\", test_adversarial_accuracy)\n  print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}