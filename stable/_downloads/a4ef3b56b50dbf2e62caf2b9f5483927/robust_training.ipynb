{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Robust Training in JAXOpt.\n\nThe following code trains a convolutional neural network (CNN) to be robust\nwith respect to the fast sign gradient (FGSM) method.\n\nThe Fast Gradient Sign Method (FGSM) is a simple yet effective method to generate\nadversarial images. It constructs an adversarial by adding a small perturbation in\nthe direction of the sign of the gradient with respect to the input. The gradient\nensures this perturbation locally maximizes the objective, while the sign ensures\nthat the update is on the boundary of the L-infinity ball.\n\n\n## References\n  Goodfellow, Ian J., Jonathon Shlens, and Christian Szegedy. \"Explaining\n  and harnessing adversarial examples.\" https://arxiv.org/abs/1412.6572\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\nfrom matplotlib import pyplot as plt\n\nimport jax\nfrom jax import numpy as jnp\n\nfrom flax import linen as nn\nimport optax\n\nfrom jaxopt import GradientDescent\nfrom jaxopt import loss\nfrom jaxopt import OptaxSolver\nfrom jaxopt import tree_util\n\n\ndef load_dataset(split, *, is_training, batch_size):\n  \"\"\"Loads the dataset as a generator of batches.\"\"\"\n  ds = tfds.load(\"mnist:3.*.*\", split=split).cache().repeat()\n  if is_training:\n    ds = ds.shuffle(10 * batch_size, seed=0)\n  ds = ds.batch(batch_size)\n  return iter(tfds.as_numpy(ds))\n\n\nclass CNN(nn.Module):\n  \"\"\"A simple CNN model.\"\"\"\n\n  @nn.compact\n  def __call__(self, x):\n    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n    x = nn.relu(x)\n    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n    x = nn.relu(x)\n    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n    x = x.reshape((x.shape[0], -1))  # flatten\n    x = nn.Dense(features=256)(x)\n    x = nn.relu(x)\n    x = nn.Dense(features=10)(x)\n    return x\n\n\nnet = CNN()\n\n\n@jax.jit\ndef accuracy(params, images, labels):\n  logits = net.apply({\"params\": params}, images)\n  return jnp.mean(jnp.argmax(logits, axis=-1) == labels)\n\n\nlogistic_loss = jax.vmap(loss.multiclass_logistic_loss)\n\n\ndef loss_fun(params, l2_regul, images, labels):\n  \"\"\"Compute the loss of the network.\"\"\"\n  logits = net.apply({\"params\": params}, images)\n  sqnorm = tree_util.tree_l2_norm(params, squared=True)\n  loss_value = jnp.mean(logistic_loss(labels, logits))\n  return loss_value + 0.5 * l2_regul * sqnorm\n\ntrain_ds = load_dataset(\"train\", is_training=True, batch_size=128)\ntest_ds = load_dataset(\"test\", is_training=False, batch_size=1000)\n\n# Initialize solver and parameters.\nsolver = OptaxSolver(opt=optax.adam(1e-3), fun=loss_fun)\nrng = jax.random.PRNGKey(0)\ninit_params = CNN().init(rng, jnp.ones([1, 28, 28, 1]))[\"params\"]\nl2_regul = 1e-4\n\nparams, state = solver.init(init_params)\nfor it in range(200):\n  data = next(train_ds)\n  images = data['image'].astype(jnp.float32) / 255\n  labels = data['label']\n\n  def fsgm_attack(image, label, epsilon=0.1):\n    \"\"\"Fast sign-gradient attack on the L-infinity ball with radius epsilon.\n    \n    Parameters:\n      image: array-like, input data for the CNN\n      label: integer, class label corresponding to image\n      epsilon: float, radius of the L-infinity ball. \n\n    Returns:\n      perturbed_image: Adversarial image on the boundary of the L-infinity ball of radius\n        epsilon and centered at image.\n    \"\"\"\n    # comppute gradient of the loss wrt to the image\n    grad = jax.grad(loss_fun, argnums=2)(params, l2_regul, image, label)\n    adv_image = image + epsilon * jnp.sign(grad)\n    # clip the image to ensure pixels are between 0 and 1\n    return jnp.clip(adv_image, 0, 1)\n\n  images_adv = fsgm_attack(images, labels)\n\n  # run adversarial training\n  params, state = solver.update(params=params, state=state,\n                             l2_regul=l2_regul, images=images_adv, labels=labels)\n  \n  if it % 10 == 0:\n    data_test = next(test_ds)\n    images_test = data_test['image'].astype(jnp.float32) / 255\n    labels_test = data_test['label']\n\n    test_accuracy = accuracy(params, images_test, labels_test)\n    print(\"Accuracy on test set\", test_accuracy)\n\n    images_adv_test = fsgm_attack(images_test, labels_test)\n    test_adversarial_accuracy = accuracy(params, images_adv_test, labels_test)\n    print(\"Accuracy on adversarial images\", test_adversarial_accuracy)\n    print()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}