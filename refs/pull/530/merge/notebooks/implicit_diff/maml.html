<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Few-shot Adaptation with Model Agnostic Meta-Learning (MAML) &mdash; JAXopt 0.8 documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/plot_directive.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-binder.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-dataframe.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/sg_gallery-rendered-html.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script src="../../_static/clipboard.min.js"></script>
        <script src="../../_static/copybutton.js"></script>
        <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            JAXopt
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../basics.html">Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../unconstrained.html">Unconstrained optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../constrained.html">Constrained optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quadratic_programming.html">Quadratic programming</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../non_smooth.html">Non-smooth optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../stochastic.html">Stochastic optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../root_finding.html">Root finding</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../fixed_point.html">Fixed point resolution</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../nonlinear_least_squares.html">Nonlinear least squares</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../linear_system_solvers.html">Linear system solving</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../implicit_diff.html">Implicit differentiation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../objective_and_loss.html">Loss and objective functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../line_search.html">Line search</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../perturbations.html">Perturbed optimization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API at a glance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Notebook gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../auto_examples/index.html">Example gallery</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">About</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/google/jaxopt/graphs/contributors">Authors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/google/jaxopt">Source code</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/google/jaxopt/issues">Issue tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../developer.html">Development</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">JAXopt</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Few-shot Adaptation with Model Agnostic Meta-Learning (MAML)</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/google/jaxopt/blob/main/docs/notebooks/implicit_diff/maml.ipynb" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <p>Copyright 2022 Google LLC</p>
<p>Licensed under the Apache License, Version 2.0 (the “License”);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span> https://www.apache.org/licenses/LICENSE-2.0
</pre></div>
</div>
<p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an “AS IS” BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</p>
<section class="tex2jax_ignore mathjax_ignore" id="few-shot-adaptation-with-model-agnostic-meta-learning-maml">
<h1>Few-shot Adaptation with Model Agnostic Meta-Learning (MAML)<a class="headerlink" href="#few-shot-adaptation-with-model-agnostic-meta-learning-maml" title="Permalink to this heading"></a></h1>
<p><a class="reference external" href="https://colab.research.google.com/github/google/jaxopt/blob/main/docs/notebooks/implicit_diff/maml.ipynb"><img alt="Open in Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<p>This notebook shows how to use Model Agnostic Meta-Learning (MAML) for few-shot adaptation on a simple regression task. This example appears in section 5.1 of <a class="reference external" href="https://arxiv.org/pdf/1703.03400.pdf">(Finn et al. 2017)</a>. The problem is however solved using <em>implicit</em> MAML formulation of <a class="reference external" href="https://arxiv.org/pdf/1909.04630.pdf">(Rajeswaran et al., 2019)</a>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="n">jaxopt</span> <span class="n">flax</span> <span class="n">matplotlib</span> <span class="n">tqdm</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Sequence</span>

<span class="c1"># activate TPUs if available</span>
<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">jax.tools.colab_tpu</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">colab_tpu</span><span class="o">.</span><span class="n">setup_tpu</span><span class="p">()</span>
<span class="k">except</span> <span class="p">(</span><span class="ne">KeyError</span><span class="p">,</span> <span class="ne">RuntimeError</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;TPU not found, continuing without it.&quot;</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">jax.config</span> <span class="kn">import</span> <span class="n">config</span>
<span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="s2">&quot;jax_enable_x64&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">jax</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">jnp</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">random</span>
<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">vmap</span>
<span class="kn">from</span> <span class="nn">jax.tree_util</span> <span class="kn">import</span> <span class="n">Partial</span><span class="p">,</span> <span class="n">tree_map</span>

<span class="kn">from</span> <span class="nn">jaxopt</span> <span class="kn">import</span> <span class="n">LBFGS</span><span class="p">,</span> <span class="n">GradientDescent</span>
<span class="kn">from</span> <span class="nn">jaxopt</span> <span class="kn">import</span> <span class="n">linear_solve</span>
<span class="kn">from</span> <span class="nn">jaxopt</span> <span class="kn">import</span> <span class="n">OptaxSolver</span>
<span class="kn">from</span> <span class="nn">jaxopt</span> <span class="kn">import</span> <span class="n">tree_util</span>

<span class="kn">import</span> <span class="nn">optax</span>

<span class="c1"># we use flax to construct a small multi-layer perceptron</span>
<span class="kn">from</span> <span class="nn">flax</span> <span class="kn">import</span> <span class="n">linen</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># for plotting</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">import</span> <span class="n">cm</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>TPU not found, continuing without it.
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/zramzi/workspace/jaxopt/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html
  from .autonotebook import tqdm as notebook_tqdm
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># default values </span>
<span class="n">n_tasks</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">MIN_X</span> <span class="o">=</span> <span class="o">-</span><span class="mi">5</span>
<span class="n">MAX_X</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># amount of L2 regularization. Higher regularization values will promote</span>
<span class="c1"># task parameters that are closer to each other.</span>
<span class="n">L2REG</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># similar to that of the paper</span>

<span class="c1"># for bigger plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">)})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">22</span><span class="p">})</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="problem-setup">
<h1>Problem setup<a class="headerlink" href="#problem-setup" title="Permalink to this heading"></a></h1>
<p>We consider a multi-task problem, where each task involves regressing from the input to the output of a sine wave. The different tasks have different amplitude and phase of the sinusoid.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_task</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">n_samples_train</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">n_samples_test</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">min_phase</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_phase</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">min_amplitude</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_amplitude</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate a toy 1-D regression dataset.&quot;&quot;&quot;</span>
    <span class="n">amplitude</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_amplitude</span> <span class="o">-</span> <span class="n">min_amplitude</span><span class="p">)</span> <span class="o">+</span> <span class="n">min_amplitude</span>
    
    <span class="n">key</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">phase</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_phase</span> <span class="o">-</span> <span class="n">min_phase</span><span class="p">)</span> <span class="o">+</span> <span class="n">min_phase</span>

    <span class="n">key</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples_train</span><span class="p">,))</span> <span class="o">*</span> <span class="p">(</span><span class="n">MAX_X</span> <span class="o">-</span> <span class="n">MIN_X</span><span class="p">)</span> <span class="o">+</span> <span class="n">MIN_X</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">x_train</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># Reshape to feed into MLP later</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x_train</span> <span class="o">-</span> <span class="n">phase</span><span class="p">)</span> <span class="o">*</span> <span class="n">amplitude</span>

    <span class="n">key</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
    <span class="n">x_test</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_samples_test</span><span class="p">,))</span> <span class="o">*</span> <span class="p">(</span><span class="n">MAX_X</span> <span class="o">-</span> <span class="n">MIN_X</span><span class="p">)</span> <span class="o">+</span> <span class="n">MIN_X</span>
    <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_test</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># Reshape to feed into MLP later</span>
    <span class="n">y_test</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x_test</span> <span class="o">-</span> <span class="n">phase</span><span class="p">)</span> <span class="o">*</span> <span class="n">amplitude</span>

    <span class="k">return</span> <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="n">phase</span><span class="p">,</span> <span class="n">amplitude</span>


<span class="c1"># the above function generates a single task</span>
<span class="c1"># the next function should generate a metabatch of tasks in a vectorized fashion (that is without a for loop)</span>
<span class="c1"># the tasks should be batched in the first dimension</span>
<span class="nd">@partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">jit</span><span class="p">,</span> <span class="n">static_argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">generate_task_batch</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">meta_batch_size</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">n_samples_train</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">n_samples_test</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">min_phase</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">max_phase</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">min_amplitude</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_amplitude</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate a batch of toy 1-D regression datasets.&quot;&quot;&quot;</span>
    <span class="n">keys</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">meta_batch_size</span><span class="p">)</span>
    <span class="n">tasks</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span>
        <span class="n">generate_task</span><span class="p">,</span>
        <span class="n">in_axes</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
    <span class="p">)(</span><span class="n">keys</span><span class="p">,</span> <span class="n">n_samples_train</span><span class="p">,</span> <span class="n">n_samples_test</span><span class="p">,</span> <span class="n">min_phase</span><span class="p">,</span> <span class="n">max_phase</span><span class="p">,</span> <span class="n">min_amplitude</span><span class="p">,</span> <span class="n">max_amplitude</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tasks</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">key</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">colors</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">Set2</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_tasks</span><span class="p">))</span>

<span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">phase</span><span class="p">,</span> <span class="n">amplitude</span> <span class="o">=</span> <span class="n">generate_task_batch</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">meta_batch_size</span><span class="o">=</span><span class="n">n_tasks</span><span class="p">)</span>
<span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_tasks</span><span class="p">):</span>

    <span class="n">phase_</span> <span class="o">=</span> <span class="n">phase</span><span class="p">[</span><span class="n">task</span><span class="p">]</span>
    <span class="n">amplitude_</span> <span class="o">=</span> <span class="n">amplitude</span><span class="p">[</span><span class="n">task</span><span class="p">]</span>

    <span class="c1"># generate the ground truth regression curve for plotting</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">MIN_X</span><span class="p">,</span> <span class="n">MAX_X</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">ys</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">xs</span><span class="o">-</span><span class="n">phase_</span><span class="p">)</span> <span class="o">*</span> <span class="n">amplitude_</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;ground truth for task </span><span class="si">{</span><span class="n">task</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">task</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">((</span><span class="n">MIN_X</span><span class="p">,</span> <span class="n">MAX_X</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper center&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># Hide the right and top spines</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="o">.</span><span class="n">right</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="o">.</span><span class="n">top</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Only show ticks on the left and bottom spines</span>
<span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
</pre></div>
</div>
<img alt="../../_images/56cd964e3ab89a392f4d03dd2ffc95abed25cbc9217ac134f9443197305f56ef.png" src="../../_images/56cd964e3ab89a392f4d03dd2ffc95abed25cbc9217ac134f9443197305f56ef.png" />
</div>
</div>
<p>We call each one of the curves above a “task”. For each task, we have access to 12 samples drawn uniformly, that we split among a train and test set of the same size.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_tasks</span><span class="p">):</span>
    <span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">task</span><span class="p">],</span> <span class="n">data_train</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">task</span><span class="p">]),</span> <span class="p">(</span><span class="n">data_test</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">task</span><span class="p">],</span> <span class="n">data_test</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">task</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Training samples for task </span><span class="si">{</span><span class="n">task</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">task</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Test samples for task </span><span class="si">{</span><span class="n">task</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">task</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper center&#39;</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="o">.</span><span class="n">right</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="o">.</span><span class="n">top</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Only show ticks on the left and bottom spines</span>
<span class="n">ax</span><span class="o">.</span><span class="n">yaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">xaxis</span><span class="o">.</span><span class="n">set_ticks_position</span><span class="p">(</span><span class="s1">&#39;bottom&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/da00c12d8ac0256014994139b368334e3aa763853e0a152958412edbd200f64b.png" src="../../_images/da00c12d8ac0256014994139b368334e3aa763853e0a152958412edbd200f64b.png" />
</div>
</div>
<p>Let <span class="math notranslate nohighlight">\(\mathcal{L_i}\)</span> (resp. <span class="math notranslate nohighlight">\(\hat{\mathcal{L_i}}\)</span>) denote the the train set (resp. test set) loss of the <span class="math notranslate nohighlight">\(i\)</span>-th task. Our goal is to learn a set of weights <span class="math notranslate nohighlight">\(\theta\)</span> such that a model trained on a new task with the regularized loss <span class="math notranslate nohighlight">\(\mathcal{L_i}(\cdot) + \frac{}{}\|\cdot - \theta\|^2\)</span> has a as small generalization error as possible.
<a class="reference external" href="https://arxiv.org/pdf/1909.04630.pdf">(Rajeswaran et al., 2019)</a> frame this as the following bi-level problem</p>
<div class="math notranslate nohighlight">
\[
\text{argmin}_{\theta} \sum_{i=1}^K \hat{\mathcal{L}_i}(x_i(\theta)) \text{ subject to } x_i(\theta) \in \text{argmin}_{x} {\mathcal{L}}_i(x) + \frac{\lambda}{2}\|x - \theta\|^2\,,
\]</div>
<p>In the following cells we’ll define the inner objective <span class="math notranslate nohighlight">\({\mathcal{L}}_i(x) + \frac{\lambda}{2}\|x - \theta\|^2\)</span> as <code class="docutils literal notranslate"><span class="pre">inner_loss</span></code> and the outer objective <span class="math notranslate nohighlight">\(\hat{\mathcal{L_i}}\)</span> as <code class="docutils literal notranslate"><span class="pre">outer_loss</span></code>. Both losses are a quadratic loss using as predictive model a multi-layer perceptron.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="n">features</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span>
  <span class="n">dtype</span><span class="p">:</span> <span class="n">Any</span>

  <span class="nd">@nn</span><span class="o">.</span><span class="n">compact</span>
  <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">inputs</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">feat</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">):</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span>
        <span class="n">feat</span><span class="p">,</span> 
        <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;layers_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> 
        <span class="n">param_dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        
      <span class="p">)(</span><span class="n">x</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">dummy_input</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SimpleMLP</span><span class="p">(</span><span class="n">features</span><span class="o">=</span><span class="p">[</span><span class="mi">40</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">jnp</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>The regressor is a neural network model with 2 hidden layers of size 40 with ReLU nonlinearities.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">inner_loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">outer_parameters</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">regularization</span><span class="o">=</span><span class="n">L2REG</span><span class="p">):</span>
  <span class="c1"># x are the task adapted parameters phi prime in the original paper</span>
  <span class="c1"># outer_parameters are the meta parameters, theta bold in the original paper</span>
  <span class="n">samples</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">data</span>
  <span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span>
  <span class="n">mse</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">prediction</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># this is L(phi_prime, D^{tr}_i)</span>
  <span class="n">x_m_outer_parameters</span> <span class="o">=</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_add_scalar_mul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">outer_parameters</span><span class="p">)</span>
  <span class="n">reg</span> <span class="o">=</span> <span class="p">(</span><span class="n">regularization</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_l2_norm</span><span class="p">(</span><span class="n">x_m_outer_parameters</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="c1"># this \lambda/2 ||phi_prime - theta_bold||^2</span>
  <span class="k">return</span> <span class="n">mse</span> <span class="o">+</span> <span class="n">reg</span>

<span class="n">inner_solver</span> <span class="o">=</span> <span class="n">GradientDescent</span><span class="p">(</span>
  <span class="n">inner_loss</span><span class="p">,</span> 
  <span class="n">stepsize</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># using line search</span>
  <span class="n">maxiter</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> 
  <span class="n">tol</span><span class="o">=</span><span class="mf">1e-12</span><span class="p">,</span> 
  <span class="n">maxls</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
  <span class="n">acceleration</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
  <span class="n">implicit_diff</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">implicit_diff_solve</span><span class="o">=</span><span class="n">Partial</span><span class="p">(</span>
      <span class="n">linear_solve</span><span class="o">.</span><span class="n">solve_cg</span><span class="p">,</span>
      <span class="n">maxiter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
      <span class="n">tol</span><span class="o">=</span><span class="mf">1e-7</span><span class="p">,</span>
  <span class="p">),</span>
<span class="p">)</span>

<span class="k">def</span> <span class="nf">outer_loss</span><span class="p">(</span><span class="n">meta_params</span><span class="p">,</span> <span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">):</span>
  <span class="c1"># inner parameters is passed </span>
  <span class="c1"># iterate on the first K-1 tasks</span>
  <span class="n">in_params_sol</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">inner_solver</span><span class="o">.</span><span class="n">run</span><span class="p">,</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">0</span><span class="p">))(</span>
    <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">meta_params</span><span class="p">),</span> 
    <span class="n">meta_params</span><span class="p">,</span> 
    <span class="n">data_train</span><span class="p">,</span>
  <span class="p">)</span>  <span class="c1"># Alg^*(\theta_bold, D^{tr}_i)</span>
  <span class="n">samples_test</span><span class="p">,</span> <span class="n">targets_test</span> <span class="o">=</span> <span class="n">data_test</span> 
  <span class="n">prediction</span> <span class="o">=</span> <span class="n">vmap</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">)(</span><span class="n">in_params_sol</span><span class="p">,</span> <span class="n">samples_test</span><span class="p">)</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">prediction</span> <span class="o">-</span> <span class="n">targets_test</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># L(\phi, D^{te}_i)</span>
  <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">in_params_sol</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">meta_params</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">init</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">dummy_input</span><span class="p">)</span>


<span class="n">gradient_subopt</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">outer_losses</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">solver</span> <span class="o">=</span> <span class="n">OptaxSolver</span><span class="p">(</span>
  <span class="n">opt</span><span class="o">=</span><span class="n">optax</span><span class="o">.</span><span class="n">adam</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">),</span> 
  <span class="n">fun</span><span class="o">=</span><span class="n">outer_loss</span><span class="p">,</span> 
  <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
  <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
  <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">phase</span><span class="p">,</span> <span class="n">amplitude</span> <span class="o">=</span> <span class="n">generate_task_batch</span><span class="p">(</span>
  <span class="n">key</span><span class="p">,</span>
  <span class="n">meta_batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
  <span class="n">n_samples_train</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
  <span class="n">n_samples_test</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">state</span> <span class="o">=</span> <span class="n">solver</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">meta_params</span><span class="p">,</span> <span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">)</span>

<span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">solver</span><span class="o">.</span><span class="n">maxiter</span><span class="p">))</span>

<span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">pbar</span><span class="p">:</span>
  <span class="n">key</span><span class="p">,</span> <span class="n">subkey</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
  <span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">,</span> <span class="n">phase</span><span class="p">,</span> <span class="n">amplitude</span> <span class="o">=</span> <span class="n">generate_task_batch</span><span class="p">(</span>
    <span class="n">key</span><span class="p">,</span>
    <span class="n">meta_batch_size</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span>
    <span class="n">n_samples_train</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> 
    <span class="n">n_samples_test</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="n">meta_params</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">solver</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">meta_params</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span><span class="p">)</span>
  <span class="n">outer_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">state</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
  <span class="n">pbar</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Outer loss </span><span class="si">{</span><span class="n">state</span><span class="o">.</span><span class="n">value</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Outer loss 0.004: 100%|██████████| 1000/1000 [00:41&lt;00:00, 24.10it/s]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xx</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">MIN_X</span><span class="p">,</span> <span class="n">MAX_X</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Training data and predictive model&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_tasks</span><span class="p">):</span>
    <span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span> <span class="o">=</span> <span class="p">(</span><span class="n">data_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">task</span><span class="p">],</span> <span class="n">data_train</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">task</span><span class="p">]),</span> <span class="p">(</span><span class="n">data_test</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">task</span><span class="p">],</span> <span class="n">data_test</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">task</span><span class="p">])</span>
    <span class="n">in_params_sol</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">inner_solver</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
        <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">meta_params</span><span class="p">),</span> 
        <span class="n">meta_params</span><span class="p">,</span> 
        <span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Training samples for task </span><span class="si">{</span><span class="n">task</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">task</span><span class="p">])</span>
    <span class="n">prediction</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">stop_gradient</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">in_params_sol</span><span class="p">,</span> <span class="n">xx</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">prediction</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">task</span><span class="p">],</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Prediction of model trained on task </span><span class="si">{</span><span class="n">task</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">phase_</span><span class="p">,</span> <span class="n">amplitude_</span> <span class="o">=</span> <span class="n">phase</span><span class="p">[</span><span class="n">task</span><span class="p">],</span> <span class="n">amplitude</span><span class="p">[</span><span class="n">task</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">amplitude_</span> <span class="o">*</span> <span class="n">jnp</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">xx</span> <span class="o">-</span> <span class="n">phase_</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;True function for task </span><span class="si">{</span><span class="n">task</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper center&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Meta-learning curve&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">outer_losses</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;outer loss&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;iterations&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/a4cd55176d441abec3eb3855e6249326c457ad1709c722926a27e5888dadb21b.png" src="../../_images/a4cd55176d441abec3eb3855e6249326c457ad1709c722926a27e5888dadb21b.png" />
<img alt="../../_images/b626d8df3353b3e40ca740b9bb389633774c9ca605603bc72193dc6dd0e8554d.png" src="../../_images/b626d8df3353b3e40ca740b9bb389633774c9ca605603bc72193dc6dd0e8554d.png" />
</div>
</div>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021-2022, the JAXopt authors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>