{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# SPMD ResNet example with Flax and JAXopt.\n\nThe purpose of this example is to illustrate how JAXopt solvers can be easily\nused for distributed training thanks to `jax.pjit`. In this case, we begin by\nimplementing data parallel training of a ResNet50 model on the ImageNet dataset\nas a fork of Flax's official ImageNet example. General aspects to pay attention\nto include:\n\n* How auxiliary information (e.g. Flax mutables, model outputs from train metrics,\n  etc) can be extracted from `loss_fun` using the `state.aux` field\n  of JAXopt's optimizer state.\n\n* How `jax.pjit` can be used to easily port single-device training loops to\n  distributed training loops.\n\nRunning on Google Cloud TPU:\n\n1. Follow the instructions in Flax's official ImageNet example to set a single\n   VM with 8 TPUs (`--accelerator_type v3-8`).\n2. Likewise, follow the instructions in Flax's official ImageNet example to\n   prepare the ImageNet dataset and ensure the `TFDS_DATA_DIR` environment\n   variable has been set appropriately.\n\n## You may finally run the example as\npython3 distributed_flax_imagenet.py --workdir=$HOME/spmd_flax_imagenet\n```\n\nNOTES: this example supports TPU pod slices (e.g. `--accelerator_type v3-32`) as\nwell as hosts with one or more GPUs attached. However, CPU-only execution is not\nyet supported.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import functools\nimport itertools\nimport os\nimport time\nfrom typing import Any, Callable, Iterator, Mapping, NamedTuple, Optional, Sequence, Type, Tuple, Union\n\nfrom absl import app\nfrom absl import flags\nfrom absl import logging\n\nfrom chex import Array, ArrayTree, Numeric, PRNGKey\n\nfrom clu import checkpoint\nfrom clu import metric_writers\nfrom clu import metrics as clu_metrics\nfrom clu import periodic_actions\n\nfrom flax import linen as nn\nfrom flax import struct\n\nimport jax\nfrom jax import numpy as jnp\nfrom jax import random\nfrom jax.sharding import Mesh\nfrom jax.sharding import PartitionSpec\nfrom jax.experimental.pjit import pjit\n\nimport jaxopt\nfrom jaxopt import tree_util\n\nimport numpy as np\nimport optax\n\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\n\n\n### Constants.\n\n# Input pipeline-related constants.\nIMAGE_SIZE = 224\nCROP_PADDING = 32\nMEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]\nSTDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n# Model-related constants.\nSUPPORTED_MODELS = ['Resnet1', 'Resnet18', 'ResNet34', 'ResNet50', 'ResNet101',\n                    'ResNet152', 'ResNet200']\nNUM_CLASSES = 1000\n\n\n### Type aliases.\nArrayDType = type[Any]\nBatch = Mapping[str, Any]\nDataIter = Iterator[Batch]\nLearningRateFn = Callable[[int], Numeric]\nMetrics = Mapping[str, Numeric]\nModuleDef = Any\n\n\n### Input flags.\n\nFLAGS = flags.FLAGS\n\nflags.DEFINE_string('workdir', None, 'Directory to store model data.')\n\nflags.DEFINE_enum('model', 'ResNet50', SUPPORTED_MODELS, 'Model to use.')\nflags.DEFINE_string('dataset', 'imagenet2012:5.*.*', 'TFDS builder name.')\n\nflags.DEFINE_float('learning_rate', 0.1, 'Learning rate.')\nflags.DEFINE_integer('warmup_epochs', 5, 'Number of warmup epochs.')\nflags.DEFINE_float('momentum', 0.9, 'Momentum.')\nflags.DEFINE_integer('batch_size', 1024, 'Global batch size.')\n\nflags.DEFINE_integer('num_epochs', 100, 'Number of training epochs.')\nflags.DEFINE_integer('log_every_steps', 100, 'Number of steps between logging.')\n\nflags.DEFINE_bool('cache', True, 'Whether to cache the dataset.')\nflags.DEFINE_bool('half_precision', True, 'Whether to use FP16.')\n\nflags.DEFINE_integer('num_train_steps', -1, 'Number of training steps.')\nflags.DEFINE_integer('steps_per_eval', -1, 'Number of steps between logging.')\n\nflags.DEFINE_integer('seed', 0, 'Seed for PRNG.')\n\n\n### Input pipeline (adapted from `flax/examples/imagenet/input_pipeline.py`).\n\n\ndef distorted_bounding_box_crop(\n    image_bytes: tf.Tensor,\n    bbox: tf.Tensor,\n    min_object_covered: Optional[Union[float, tf.Tensor]] = 0.1,\n    aspect_ratio_range: Optional[Sequence[float]] = (0.75, 1.33),\n    area_range: Optional[Sequence[float]] = (0.05, 1.0),\n    max_attempts: Optional[int] = 100,\n) -> tf.Tensor:\n  \"\"\"Generates cropped_image using one of the bboxes randomly distorted.\n\n  See `tf.image.sample_distorted_bounding_box` for more documentation.\n\n  Args:\n    image_bytes: `Tensor` of binary image data.\n    bbox: `Tensor` of bounding boxes arranged `[1, num_boxes, coords]`\n        where each coordinate is [0, 1) and the coordinates are arranged\n        as `[ymin, xmin, ymax, xmax]`. If num_boxes is 0 then use the whole\n        image.\n    min_object_covered: An optional `float`. Defaults to `0.1`. The cropped\n        area of the image must contain at least this fraction of any bounding\n        box supplied.\n    aspect_ratio_range: An optional list of `float`s. The cropped area of the\n        image must have an aspect ratio = width / height within this range.\n    area_range: An optional list of `float`s. The cropped area of the image\n        must contain a fraction of the supplied image within in this range.\n    max_attempts: An optional `int`. Number of attempts at generating a cropped\n        region of the image of the specified constraints. After `max_attempts`\n        failures, return the entire image.\n  Returns:\n    cropped image `Tensor`\n  \"\"\"\n  shape = tf.io.extract_jpeg_shape(image_bytes)\n  sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(\n      shape,\n      bounding_boxes=bbox,\n      min_object_covered=min_object_covered,\n      aspect_ratio_range=aspect_ratio_range,\n      area_range=area_range,\n      max_attempts=max_attempts,\n      use_image_if_no_bounding_boxes=True)\n  bbox_begin, bbox_size, _ = sample_distorted_bounding_box\n\n  # Crop the image to the specified bounding box.\n  offset_y, offset_x, _ = tf.unstack(bbox_begin)\n  target_height, target_width, _ = tf.unstack(bbox_size)\n  crop_window = tf.stack([offset_y, offset_x, target_height, target_width])\n  image = tf.io.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n\n  return image\n\n\ndef _resize(image, image_size):\n  return tf.image.resize([image], [image_size, image_size],\n                         method=tf.image.ResizeMethod.BICUBIC)[0]\n\n\ndef _at_least_x_are_equal(a, b, x):\n  \"\"\"At least `x` of `a` and `b` `Tensors` are equal.\"\"\"\n  match = tf.equal(a, b)\n  match = tf.cast(match, tf.int32)\n  return tf.greater_equal(tf.reduce_sum(match), x)\n\n\ndef _decode_and_random_crop(image_bytes, image_size):\n  \"\"\"Make a random crop of image_size.\"\"\"\n  bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\n  image = distorted_bounding_box_crop(\n      image_bytes,\n      bbox,\n      min_object_covered=0.1,\n      aspect_ratio_range=(3. / 4, 4. / 3.),\n      area_range=(0.08, 1.0),\n      max_attempts=10)\n  original_shape = tf.io.extract_jpeg_shape(image_bytes)\n  bad = _at_least_x_are_equal(original_shape, tf.shape(image), 3)\n\n  image = tf.cond(\n      bad,\n      lambda: _decode_and_center_crop(image_bytes, image_size),\n      lambda: _resize(image, image_size))\n\n  return image\n\n\ndef _decode_and_center_crop(image_bytes, image_size):\n  \"\"\"Crops to center of image with padding then scales image_size.\"\"\"\n  shape = tf.io.extract_jpeg_shape(image_bytes)\n  image_height = shape[0]\n  image_width = shape[1]\n\n  padded_center_crop_size = tf.cast(\n      ((image_size / (image_size + CROP_PADDING)) *\n       tf.cast(tf.minimum(image_height, image_width), tf.float32)),\n      tf.int32)\n\n  offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n  offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n  crop_window = tf.stack([offset_height, offset_width,\n                          padded_center_crop_size, padded_center_crop_size])\n  image = tf.io.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n  image = _resize(image, image_size)\n\n  return image\n\n\ndef normalize_image(image: tf.Tensor) -> tf.Tensor:\n  image -= tf.constant(MEAN_RGB, shape=[1, 1, 3], dtype=image.dtype)\n  image /= tf.constant(STDDEV_RGB, shape=[1, 1, 3], dtype=image.dtype)\n  return image\n\n\ndef create_split(\n    dataset_builder: tfds.core.DatasetBuilder,\n    batch_size: int,\n    train: bool,\n    dtype: tf.DType = tf.float32,\n    image_size: int = IMAGE_SIZE,\n    cache: bool = False,\n) -> tf.data.Dataset:\n  \"\"\"Creates a split from the ImageNet dataset using TensorFlow Datasets.\n\n  Args:\n    dataset_builder: TFDS dataset builder for ImageNet.\n    batch_size: the batch size returned by the data pipeline.\n    train: whether to load the train or evaluation split.\n    dtype: data type of the image.\n    image_size: the target size of the images.\n    cache: whether to cache the dataset.\n  Returns:\n    A `tf.data.Dataset`.\n  \"\"\"\n  split = 'train' if train else 'validation'\n  num_examples = dataset_builder.info.splits[split].num_examples\n  split_size = num_examples // jax.process_count()\n  start = jax.process_index() * split_size\n  split = f'{split}[{start}:{start + split_size}]'\n\n  def decode_example(example):\n    decode_fn = _decode_and_random_crop if train else _decode_and_center_crop\n    image = decode_fn(example['image'], image_size)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    if train:\n      image = tf.image.random_flip_left_right(image)\n    image = normalize_image(image)\n    image = tf.image.convert_image_dtype(image, dtype=dtype)\n    return {'image': image, 'label': example['label']}\n\n  ds = dataset_builder.as_dataset(\n      split=split,\n      decoders={'image': tfds.decode.SkipDecoding()},\n  )\n  options = tf.data.Options()\n  options.experimental_threading.private_threadpool_size = 48\n  ds = ds.with_options(options)\n\n  if cache:\n    ds = ds.cache()\n\n  if train:\n    ds = ds.repeat()\n    ds = ds.shuffle(16 * batch_size, seed=0)\n\n  ds = ds.map(decode_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n  ds = ds.batch(batch_size, drop_remainder=True)\n\n  if not train:\n    ds = ds.repeat()\n\n  return ds.prefetch(10)\n\n\ndef create_input_iterators(\n    dataset_builder: tfds.core.DatasetBuilder,\n    batch_size: int,\n    half_precision: bool = True,\n    image_size: int = IMAGE_SIZE,\n    cache: bool = False,\n) -> Tuple[DataIter, DataIter]:\n  \"\"\"Returns train and evaluation data iterators.\n\n  Args:\n    dataset_builder: TFDS dataset builder for ImageNet.\n    batch_size: the (local) batch size returned by the data pipeline.\n    half_precision: whether to use FP16..\n    image_size: the target size of the images.\n    cache: whether to cache the dataset.\n\n  Returns:\n    A tuple of `tf.data.Dataset` iterators over minibatches.\n  \"\"\"\n  input_dtype = tf.float32\n  if half_precision:\n    platform = jax.local_devices()[0].platform\n    input_dtype = tf.bfloat16 if platform == 'tpu' else tf.float16\n\n  train_ds = create_split(\n      dataset_builder, batch_size, True, input_dtype, image_size, cache)\n  eval_ds = create_split(\n      dataset_builder, batch_size, False, input_dtype, image_size, cache)\n\n  train_ds, eval_ds = train_ds.as_numpy_iterator(), eval_ds.as_numpy_iterator()\n  return iter(train_ds), iter(eval_ds)\n\n\n### Model (adapted from `flax/examples/imagenet/models.py`).\n\n\nclass ResNetBlock(nn.Module):\n  \"\"\"ResNet block.\"\"\"\n  filters: int\n  conv: ModuleDef\n  norm: ModuleDef\n  act: Callable\n  strides: Tuple[int, int] = (1, 1)\n\n  @nn.compact\n  def __call__(self, x,):\n    residual = x\n    y = self.conv(self.filters, (3, 3), self.strides)(x)\n    y = self.norm()(y)\n    y = self.act(y)\n    y = self.conv(self.filters, (3, 3))(y)\n    y = self.norm(scale_init=nn.initializers.zeros)(y)\n\n    if residual.shape != y.shape:\n      residual = self.conv(self.filters, (1, 1),\n                           self.strides, name='conv_proj')(residual)\n      residual = self.norm(name='norm_proj')(residual)\n\n    return self.act(residual + y)\n\n\nclass BottleneckResNetBlock(nn.Module):\n  \"\"\"Bottleneck ResNet block.\"\"\"\n  filters: int\n  conv: ModuleDef\n  norm: ModuleDef\n  act: Callable\n  strides: Tuple[int, int] = (1, 1)\n\n  @nn.compact\n  def __call__(self, x):\n    residual = x\n    y = self.conv(self.filters, (1, 1))(x)\n    y = self.norm()(y)\n    y = self.act(y)\n    y = self.conv(self.filters, (3, 3), self.strides)(y)\n    y = self.norm()(y)\n    y = self.act(y)\n    y = self.conv(self.filters * 4, (1, 1))(y)\n    y = self.norm(scale_init=nn.initializers.zeros)(y)\n\n    if residual.shape != y.shape:\n      residual = self.conv(self.filters * 4, (1, 1),\n                           self.strides, name='conv_proj')(residual)\n      residual = self.norm(name='norm_proj')(residual)\n\n    return self.act(residual + y)\n\n\nclass ResNet(nn.Module):\n  \"\"\"ResNetV1.\"\"\"\n  stage_sizes: Sequence[int]\n  block_cls: ModuleDef\n  num_classes: int\n  num_filters: int = 64\n  dtype: Any = jnp.float32\n  act: Callable = nn.relu\n\n  @nn.compact\n  def __call__(self, x, train: bool = True):\n    conv = functools.partial(nn.Conv, use_bias=False, dtype=self.dtype)\n    norm = functools.partial(nn.BatchNorm,\n                             use_running_average=not train,\n                             momentum=0.9,\n                             epsilon=1e-5,\n                             dtype=self.dtype)\n\n    x = conv(self.num_filters, (7, 7), (2, 2),\n             padding=[(3, 3), (3, 3)],\n             name='conv_init')(x)\n    x = norm(name='bn_init')(x)\n    x = nn.relu(x)\n    x = nn.max_pool(x, (3, 3), strides=(2, 2), padding='SAME')\n    for i, block_size in enumerate(self.stage_sizes):\n      for j in range(block_size):\n        strides = (2, 2) if i > 0 and j == 0 else (1, 1)\n        x = self.block_cls(self.num_filters * 2 ** i,\n                           strides=strides,\n                           conv=conv,\n                           norm=norm,\n                           act=self.act)(x)\n    x = jnp.mean(x, axis=(1, 2))\n    x = nn.Dense(self.num_classes, dtype=self.dtype)(x)\n    x = jnp.asarray(x, self.dtype)\n    return x\n\n\nMODELS = {\n    'ResNet1': functools.partial(\n        ResNet, stage_sizes=[1], block_cls=ResNetBlock),\n    'ResNet18': functools.partial(\n        ResNet, stage_sizes=[2, 2, 2, 2], block_cls=ResNetBlock),\n    'ResNet34': functools.partial(\n        ResNet, stage_sizes=[3, 4, 6, 3], block_cls=ResNetBlock),\n    'ResNet50': functools.partial(\n        ResNet, stage_sizes=[3, 4, 6, 3], block_cls=BottleneckResNetBlock),\n    'ResNet101': functools.partial(\n        ResNet, stage_sizes=[3, 4, 23, 3], block_cls=BottleneckResNetBlock),\n    'ResNet152': functools.partial(\n        ResNet, stage_sizes=[3, 8, 36, 3], block_cls=BottleneckResNetBlock),\n    'ResNet200': functools.partial(\n        ResNet, stage_sizes=[3, 24, 36, 3], block_cls=BottleneckResNetBlock),\n}\n\n\n### SPMD utilities.\n\n\ndef setup_data_parallel_mesh():\n  global_mesh = Mesh(np.asarray(jax.devices(), dtype=object), ['data'])\n  jax.experimental.maps.thread_resources.env = (\n      jax.experimental.maps.ResourceEnv(physical_mesh=global_mesh, loops=()))\n\n\n### Training loop utilities.\n\n\nclass LossFnAux(NamedTuple):\n  \"\"\"Stores auxiliary values computed during loss function eval for reuse.\"\"\"\n  batch_stats: ArrayTree\n  logits: Array\n\n\ndef cross_entropy_loss(labels, logits, **_):\n  xentropy = jax.vmap(jaxopt.loss.multiclass_logistic_loss)(labels, logits)\n  return jnp.mean(xentropy)\n\n\ndef loss_fun(\n    params: ArrayTree,\n    batch_stats: ArrayTree,\n    batch: Batch,\n    model: nn.Module,\n    weight_decay: float = 1e-4,\n) -> Tuple[Numeric, LossFnAux]:\n  \"\"\"Loss function used for training.\"\"\"\n  logits, new_mutable_variables = model.apply(\n      {'params': params, 'batch_stats': batch_stats},\n      batch['image'],\n      mutable=['batch_stats'])\n\n  xentropy = cross_entropy_loss(labels=batch['label'], logits=logits)\n  weight_penalty_params = [x for x in jax.tree_leaves(params) if x.ndim > 1]\n  weight_l2 = tree_util.tree_l2_norm(weight_penalty_params, squared=True)\n  loss = xentropy + weight_decay * 0.5 * weight_l2\n\n  new_batch_stats = new_mutable_variables['batch_stats']\n  aux = LossFnAux(batch_stats=new_batch_stats, logits=logits)\n\n  return loss, aux\n\n\n@struct.dataclass\nclass TrainMetrics(clu_metrics.Collection):\n\n  accuracy: clu_metrics.Accuracy\n  learning_rate: clu_metrics.Average.from_output('learning_rate')\n  loss: clu_metrics.Average.from_output('loss')\n  xent: clu_metrics.Average.from_fun(cross_entropy_loss)\n\n\n@struct.dataclass\nclass EvalMetrics(clu_metrics.Collection):\n\n  accuracy: clu_metrics.Accuracy\n  xent: clu_metrics.Average.from_fun(cross_entropy_loss)\n\n\ndef train_step(\n    params: ArrayTree,\n    state: ArrayTree,\n    batch: Batch,\n    metrics: Optional[TrainMetrics],\n    learning_rate_fn: LearningRateFn,\n    solver: jaxopt.OptaxSolver,\n) -> Tuple[ArrayTree, ArrayTree, TrainMetrics]:\n  \"\"\"Performs a single training step.\"\"\"\n  # Retrieves Flax mutables from previous step, stored in `state.aux`.\n  batch_stats = state.aux.batch_stats\n  # Computes updated model parameters and optimizer state.\n  params, state = solver.update(\n      params=params,\n      state=state,\n      batch_stats=batch_stats,\n      batch=batch,\n  )\n  # Computes train metrics for `batch`, re-using the auxiliary outputs from\n  # `loss_fun` (e.g. logits) that are stored in `state.aux``.\n  new_metrics = TrainMetrics.single_from_model_output(\n      logits=state.aux.logits,\n      labels=batch['label'],\n      learning_rate=learning_rate_fn(state.iter_num),\n      loss=state.value,  # xentropy + L2 regularization.\n  )\n  # Accumulates train metrics for current batch into history.\n  if metrics is None:\n    metrics = new_metrics\n  else:\n    metrics = metrics.merge(new_metrics)\n\n  return params, state, metrics\n\n\ndef eval_step(\n    params: ArrayTree,\n    state: ArrayTree,\n    batch: Batch,\n    metrics: Optional[EvalMetrics],\n    model: nn.Module,\n) -> EvalMetrics:\n  \"\"\"Performs a single evaluation step.\"\"\"\n  # Retrieves Flax mutables from last train step, stored in `state.aux`.\n  batch_stats = state.aux.batch_stats\n  # Computes model outputs in inference-mode.\n  variables = {'params': params, 'batch_stats': batch_stats}\n  logits = model.apply(\n      variables, batch['image'], train=False, mutable=False)\n  # Computes eval metrics for `batch`.\n  new_metrics = EvalMetrics.single_from_model_output(\n      logits=logits, labels=batch['label'])\n  # Accumulates eval metrics for current batch into history.\n  if metrics is None:\n    metrics = new_metrics\n  else:\n    metrics = metrics.merge(new_metrics)\n\n  return metrics\n\n\ndef create_model(\n    model_cls: Type[nn.Module],\n    num_classes: int = NUM_CLASSES,\n    half_precision: bool = True,\n    **kwargs,\n) -> nn.Module:\n  \"\"\"Creates FLAX model.\"\"\"\n  model_dtype = jnp.float32\n  if half_precision:\n    platform = jax.local_devices()[0].platform\n    model_dtype = jnp.bfloat16 if platform == 'tpu' else jnp.float16\n  return model_cls(num_classes=num_classes, dtype=model_dtype, **kwargs)\n\n\ndef initialize_model(\n    key: PRNGKey,\n    model: nn.Module,\n    image_size: int = IMAGE_SIZE,\n) -> Tuple[ArrayTree, ArrayTree]:\n  \"\"\"Initializes FLAX model, returning params and mutable variables.\"\"\"\n  input_shape = (1, image_size, image_size, 3)\n  @jax.jit\n  def init(*args):\n    return model.init(*args)\n  variables = init({'params': key}, jnp.ones(input_shape, model.dtype))\n\n  return variables['params'], variables['batch_stats']\n\n\ndef create_learning_rate_fn(\n    learning_rate: float,\n    batch_size: int,\n    steps_per_epoch: int,\n    warmup_epochs: int,\n    num_epochs: int,\n) -> LearningRateFn:\n  \"\"\"Creates learning rate schedule.\"\"\"\n  base_learning_rate = learning_rate * batch_size / 256.\n  warmup_fn = optax.linear_schedule(\n      init_value=0., end_value=base_learning_rate,\n      transition_steps=warmup_epochs * steps_per_epoch)\n  cosine_epochs = max(num_epochs - warmup_epochs, 1)\n  cosine_fn = optax.cosine_decay_schedule(\n      init_value=base_learning_rate,\n      decay_steps=cosine_epochs * steps_per_epoch)\n  schedule_fn = optax.join_schedules(\n      schedules=[warmup_fn, cosine_fn],\n      boundaries=[warmup_epochs * steps_per_epoch])\n  return schedule_fn\n\n\ndef create_solver(\n    learning_rate_fn: LearningRateFn,\n    momentum: float,\n    model: nn.Module,\n) -> jaxopt.OptaxSolver:\n  \"\"\"Creates JAXopt solver.\"\"\"\n  opt = optax.sgd(learning_rate=learning_rate_fn,\n                  momentum=momentum,\n                  nesterov=True)\n  fun = functools.partial(loss_fun, model=model)\n  return jaxopt.OptaxSolver(opt=opt, fun=fun, has_aux=True)\n\n\ndef zeros_like_fun_output(\n    fun: Callable,\n    index: Optional[int] = None,\n) -> Callable:\n  \"\"\"Replaces fun, outputting a pytree of zeroes with the original structure.\"\"\"\n  def wrapper(*args, **kwargs):\n    pytree = jax.eval_shape(fun, *args, **kwargs)\n    leaves, treedef = jax.tree_flatten(pytree)\n    leaves = [jnp.zeros(shape=leaf.shape, dtype=leaf.dtype) for leaf in leaves]\n    zeros_like_pytree = jax.tree_unflatten(treedef, leaves)\n    return zeros_like_pytree if index is None else zeros_like_pytree[index]\n  return wrapper\n\n\ndef initialize_solver(\n    solver: jaxopt.OptaxSolver,\n    init_params: ArrayTree,\n    init_batch_stats: ArrayTree,\n    first_batch: Batch,\n    model: nn.Module,\n) -> ArrayTree:\n  \"\"\"Initializes the state of jaxopt.OptaxSolver.\"\"\"\n  # \"Default\" JAXopt initial optimizer state.\n  state = solver.init_state(init_params)\n\n  # To prevent `train_step` from being compiled twice, we must ensure all its\n  # input arguments have the same shape and dtype in all calls. To this end,\n  # we will\n  #   1) Initialize `state.aux` with a Pytree of the right shape and dtype.\n  #   2) Ensure that `state.value` and `state.error` are strongly typed.\n  zeros_like_loss_fun = zeros_like_fun_output(\n      functools.partial(loss_fun, model=model))\n  init_loss, init_aux = zeros_like_loss_fun(\n      init_params, init_batch_stats, first_batch)\n  init_aux = init_aux._replace(batch_stats=init_batch_stats)\n  loss_dtype = init_loss.dtype\n  return state._replace(\n      value=jnp.asarray(jnp.inf, dtype=loss_dtype),\n      error=jnp.asarray(jnp.inf, dtype=loss_dtype),\n      aux=init_aux)\n\n\ndef initialize_metrics(\n    init_params: ArrayTree,\n    init_state: ArrayTree,\n    first_batch: Batch,\n    learning_rate_fn: LearningRateFn,\n    solver: jaxopt.OptaxSolver,\n    model: nn.Module,\n) -> Tuple[TrainMetrics, EvalMetrics]:\n  \"\"\"Initializes train and eval metric accumulators.\"\"\"\n  # To prevent `train_step` and `eval_step` from being compiled twice, we must\n  # ensure all its input arguments have the same shape and dtype in all calls.\n  # To this end, we will initialize the `train_metrics` and `eval_metrics`\n  # accumulators with Pytrees of the right shape and dtype but containing all\n  # zeroes (including for the `count` field).\n  zeros_like_train_step_fun = zeros_like_fun_output(\n      functools.partial(\n          train_step, learning_rate_fn=learning_rate_fn, solver=solver),\n      index=-1)\n  zeros_like_eval_step_fun = zeros_like_fun_output(\n      functools.partial(eval_step, model=model))\n\n  train_metrics_init = zeros_like_train_step_fun(\n      init_params, init_state, first_batch, None)\n  eval_metrics_init = zeros_like_eval_step_fun(\n      init_params, init_state, first_batch, None)\n\n  return train_metrics_init, eval_metrics_init\n\n\n### Training loop.\n\n\ndef train_and_evaluate(workdir: str, seed: int = 0):\n  \"\"\"Execute model training and evaluation loop.\n\n  Args:\n    workdir: Directory where the tensorboard summaries are written to.\n    seed: Initial seed for the PRNG.\n\n  Returns:\n    Final OptState.\n  \"\"\"\n  # Sets PRNG seed (same in all hosts and devices).\n  rng = random.PRNGKey(seed)\n\n  # Computes local (i.e. per-device) batch size.\n  if FLAGS.batch_size % jax.device_count() > 0:\n    raise ValueError('Batch size must be divisible by the number of devices')\n  local_batch_size = FLAGS.batch_size // jax.process_count()\n\n  # Obtains iterators for training and evaluation datasets.\n  ds_builder = tfds.builder(FLAGS.dataset)\n  train_iter, eval_iter = create_input_iterators(ds_builder,\n                                                 local_batch_size,\n                                                 FLAGS.half_precision,\n                                                 IMAGE_SIZE,\n                                                 FLAGS.cache)\n\n  # Computes period, in number of steps, for logging, evaluation and\n  # checkpointing.\n  num_train_examples = ds_builder.info.splits['train'].num_examples\n  num_validation_examples = ds_builder.info.splits['validation'].num_examples\n  steps_per_epoch = num_train_examples // FLAGS.batch_size\n  num_train_steps = FLAGS.num_train_steps\n  if num_train_steps == -1:\n    num_train_steps = int(steps_per_epoch * FLAGS.num_epochs)\n  steps_per_eval = FLAGS.steps_per_eval\n  if steps_per_eval == -1:\n    steps_per_eval = num_validation_examples // FLAGS.batch_size\n  steps_per_checkpoint = steps_per_epoch * 10\n\n  # Retrieves the first batch from the training iterator, to be used for\n  # initialization purposes, and puts it back into the iterator.\n  first_batch = next(train_iter)\n  train_iter = itertools.chain([first_batch], train_iter)\n\n  # Creates Flax model and initializes its parameters and mutable variables.\n  model = create_model(MODELS[FLAGS.model], NUM_CLASSES, FLAGS.half_precision)\n  params, batch_stats = initialize_model(rng, model, IMAGE_SIZE)\n\n  # Creates learning rate schedule.\n  learning_rate_fn = create_learning_rate_fn(FLAGS.learning_rate,\n                                             FLAGS.batch_size,\n                                             steps_per_epoch,\n                                             FLAGS.warmup_epochs,\n                                             FLAGS.num_epochs)\n  # Creates a JAXopt optimizer and initializes its state with special care to\n  # avoid recompilations.\n  solver = create_solver(learning_rate_fn, FLAGS.momentum, model)\n  state = initialize_solver(solver, params, batch_stats, first_batch, model)\n\n  # Initializes accumulators for train and eval metrics and defines inline util\n  # for replicating them across devices, also to prevent recompilations.\n  train_metrics_init, eval_metrics_init = initialize_metrics(\n      params, state, first_batch, learning_rate_fn, solver, model)\n  replicate_metrics_init = pjit(\n      lambda t: t, in_shardings=None, out_shardings=None\n  )\n\n  # Compiles data parallel train and eval steps using `jax.pjit`.\n  p_train_step = pjit(\n      functools.partial(\n          train_step, learning_rate_fn=learning_rate_fn, solver=solver\n      ),\n      in_shardings=(None, None, PartitionSpec('data'), None),\n      out_shardings=None,\n  )\n  p_eval_step = pjit(\n      functools.partial(eval_step, model=model),\n      in_shardings=(None, None, PartitionSpec('data'), None),\n      out_shardings=None,\n  )\n\n  # Instantiates metrics writer for logging.\n  writer = metric_writers.create_default_writer(\n      logdir=workdir, just_logging=jax.process_index() != 0)\n\n  # Instantiates checkpointer manager and tries to restore state from `workdir`.\n  ckpt = checkpoint.MultihostCheckpoint(\n      os.path.join(workdir, 'checkpoints'), max_to_keep=3)\n  params, state = ckpt.restore_or_initialize((params, state))\n  step_offset = int(state.iter_num)\n\n  # Sets up callbacks.\n  report_progress = periodic_actions.ReportProgress(\n      num_train_steps=num_train_steps, writer=writer)\n  hooks = [report_progress]\n  if jax.process_index() == 0:\n    hooks += [periodic_actions.Profile(num_profile_steps=5, logdir=workdir)]\n\n  # Runs training loop.\n  train_metrics = replicate_metrics_init(train_metrics_init)\n  tic = time.time()\n  for step, batch in zip(range(step_offset, num_train_steps), train_iter):\n    params, state, train_metrics = p_train_step(\n        params, state, batch, train_metrics)\n\n    if step == step_offset:\n      time_elapsed = time.time() - tic\n      logging.info('p_train_step compilation done in %.2f s.', time_elapsed)\n\n    for h in hooks:\n      h(step)\n\n    if (step + 1) % FLAGS.log_every_steps == 0 or step + 1 == num_train_steps:\n      summary = train_metrics.compute()\n      writer.write_scalars(\n          step + 1, {f'train_{key}': val for key, val in summary.items()})\n      # Resets accumulator for train metrics.\n      train_metrics = replicate_metrics_init(train_metrics_init)\n\n    if (step + 1) % steps_per_epoch == 0:\n      with report_progress.timed('evaluation'):\n        eval_metrics = replicate_metrics_init(eval_metrics_init)\n        for _, eval_batch in zip(range(steps_per_eval), eval_iter):\n          eval_metrics = p_eval_step(params, state, eval_batch, eval_metrics)\n\n        summary = eval_metrics.compute()\n        writer.write_scalars(\n            step + 1, {f'eval_{key}': val for key, val in summary.items()})\n        writer.flush()\n\n    if (step + 1) % steps_per_checkpoint == 0 or step + 1 == num_train_steps:\n      with report_progress.timed('checkpointing'):\n        ckpt.save((params, state))\n\n  # Wait until computations are done before exiting\n  jax.random.normal(jax.random.PRNGKey(0), ()).block_until_ready()\n\n  return params, state\n\n\n### Entry point.\n\n\ndef main(_):\n  tf.config.experimental.set_visible_devices([], 'GPU')\n\n  logging.info('JAX process: %d / %d', jax.process_index(), jax.process_count())\n  logging.info('JAX local devices: %r', jax.local_devices())\n\n  setup_data_parallel_mesh()\n  logging.info('JAX PJIT mesh: %s', jax.experimental.maps.thread_resources.env)\n\n  return train_and_evaluate(FLAGS.workdir)\n\n\nif __name__ == '__main__':\n  app.run(main)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}