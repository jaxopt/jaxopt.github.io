{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Anderson acceleration of block coordinate descent.\n\nBlock coordinate descent converges to a fixed point. It can therefore be\naccelerated with Anderson acceleration.\n\nHere `m` denotes the history size, and `K` the frequency of Anderson updates.\n\nBertrand, Q. and Massias, M.\nAnderson acceleration of coordinate descent.\nAISTATS, 2021.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import jax\nimport jax.numpy as jnp\n\nfrom jaxopt import AndersonWrapper\nfrom jaxopt import BlockCoordinateDescent\n\nfrom jaxopt import objective\nfrom jaxopt import prox\n\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\n\njax.config.update(\"jax_platform_name\", \"cpu\")\njax.config.update(\"jax_enable_x64\", True)\n\n\n# retrieve intermediate iterates.\ndef run_all(solver, w_init, *args, **kwargs):\n  state = solver.init_state(w_init, *args, **kwargs)\n  sol = w_init\n  sols, errors = [sol], [state.error]\n  for _ in range(solver.maxiter):\n    sol, state = solver.update(sol, state, *args, **kwargs)\n    sols.append(sol)\n    errors.append(state.error)\n  return jnp.stack(sols, axis=0), errors\n\n\nX, y = datasets.make_regression(n_samples=10, n_features=8, random_state=1)\nfun = objective.least_squares  # fun(params, data)\nl1reg = 10.0\ndata = (X, y)\n\nw_init = jnp.zeros(X.shape[1])\nmaxiter = 80\n\nbcd = BlockCoordinateDescent(fun, block_prox=prox.prox_lasso, maxiter=maxiter, tol=1e-6)\nhistory_size = 5\naa = AndersonWrapper(bcd, history_size=history_size, mixing_frequency=1, ridge=1e-4)\naam = AndersonWrapper(bcd, history_size=history_size, mixing_frequency=history_size, ridge=1e-4)\n\naa_sols, aa_errors = run_all(aa, w_init, hyperparams_prox=l1reg, data=data)\naam_sols, aam_errors = run_all(aam, w_init, hyperparams_prox=l1reg, data=data)\nbcd_sols, bcd_errors = run_all(bcd, w_init, hyperparams_prox=l1reg, data=data)\n\nprint(f'Error={aa_errors[-1]:.6f} at parameters {aa_sols[-1]} for Anderson (m=5, K=1)')\nprint(f'Error={aam_errors[-1]:.6f} at parameters {aam_sols[-1]} for Anderson (m=5, K=5)')\nprint(f'Error={bcd_errors[-1]:.6f} at parameters {bcd_sols[-1]} for Block CD')\n\nfig = plt.figure(figsize=(10, 12))\nfig.suptitle('Least Square linear regression with Lasso penalty')\nspec = fig.add_gridspec(ncols=2, nrows=3, hspace=0.3)\n\n# Plot trajectory in parameter space (8 dimensions)\nfor i in range(4):\n  ax = fig.add_subplot(spec[i//2, i%2])\n  ax.plot(bcd_sols[:,i], bcd_sols[:,2*i+1], '--', label=\"Coordinate Descent\")\n  ax.plot(aa_sols[:,i], aa_sols[:,2*i+1], '--', label=\"Anderson Accelerated CD (m=5, K=1)\")\n  ax.plot(aam_sols[:,i], aam_sols[:,2*i+1], '--', label=\"Anderson Accelerated CD (m=5, K=5)\")\n  ax.set_xlabel(f'$x_{{{2*i+1}}}$')\n  ax.set_ylabel(f'$x_{{{2*i+2}}}$')\n  if i == 0:\n    ax.legend(loc='upper left', bbox_to_anchor=(0.75, 1.38),\n              ncol=1, fancybox=True, shadow=True)\n  ax.axis('equal')\n\n# Plot error as function of iteration num\nax = fig.add_subplot(spec[2, :])\niters = jnp.arange(len(aa_errors))\nax.plot(iters, bcd_errors, '-o', label='Coordinate Descent Error')\nax.plot(iters, aa_errors, '-o', label='Anderson Accelerated CD Error (m=5, K=1)')\nax.plot(iters, aam_errors, '-o', label='Anderson Accelerated CD Error (m=5, K=5)')\nax.set_xlabel('Iteration num')\nax.set_ylabel('Error')\nax.set_yscale('log')\nax.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}